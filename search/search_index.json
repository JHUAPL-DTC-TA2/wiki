{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DTC Participant AWS User Guide","text":"<p>This user guide provides step-by-step instructions to configure your AWS WorkSpace and AWS SageMaker environment as well as troubleshooting notes for common issues. Contact the JHU APL team if you have any questions at APL-DTC-Help@jhuapl.edu.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Tutorials<ul> <li>Configuring your WorkSpace</li> <li>Connecting to your team's SageMaker Studio</li> <li>Quick Start SageMaker Studio</li> <li>Transfer data to and from S3 buckets</li> </ul> </li> </ul>"},{"location":"#tutorials","title":"Tutorials","text":""},{"location":"#configuring-your-workspace","title":"Configuring your WorkSpace","text":"<p>AWS WorkSpace is a Desktop-As-A-Service platform that streams a virtualized desktop environment to your local machine. For this challenge, we use WorkSpaces to provide participants a pre-configured, secure environment to access DTC data and computing resources to develop their models. </p> <p>Currently, all participants will use the same WorkSpace bundle: Ubuntu 22.04 Power Bundle (4 vCPU, 16 GiB RAM) with the following pre-installed libraries and programs: FireFox, Python 3.9, VSCode, and MySQL WorkBench. We may change the default bundle or provide alternative bundles in the future. </p> <p>Once you are permitted to participate in the TA2 challenge, you should receive two emails contain information about accessing WorkSpaces and SageMaker domain. The WorkSpaces email will look similar to the one show below and contains the information you need to configure your WorkSpace.</p> <p>Dear Amazon WorkSpaces User,</p> <p>Your administrator has created an Amazon WorkSpace for you. Follow the steps below to quickly get started with your WorkSpace:</p> <ol> <li> <p>Complete your user profile and download a WorkSpaces client using the following link:  <li> <p>Launch the client and enter the following registration code:  <li> <p>Login with your newly created password. Your username is  <p>You may download clients for additional devices at https://clients.amazonworkspaces.com/</p> <p>If you have any issues connecting to your WorkSpace, please contact your administrator.</p> <p>Sincerely,</p> <p>Amazon WorkSpaces </p> <p>Follow the steps below to finish setting up your WorkSpace.    </p> <ol> <li> <p>Click the link for your user profile and create a password for your account. Account passwords can be reset by an administrator or through the client. <p></p></p> </li> <li> <p>If you haven't already, download and install the WorkSpaces client at https://clients.amazonworkspaces.com/. The WorkSpaces client is compatible with most operating systems.</p> </li> <li> <p>Open the WorkSpace client and input your registration code in the in the input box.     <p></p></p> </li> <li> <p>Log-in using the username from the WorkSpaces email and the password you created in Step 1. <p></p></p> </li> <li> <p>Once you successfully log-in, the client will expand to fill your screen and load your WorkSpace. On its first load, this may take a couple minutes to fully initialize. If you have a multi-monitor or high-resolution screen, the WorkSpace desktop may seem zoomed-out or cropped. Closing the client and re-logging in sometimes helps with this issue. If the issue persists, disable High-DPI mode in Settings -&gt; Display Settings.     <p></p></p> </li> </ol> <p>That's it! A couple of additional points:    </p> <ul> <li>The default WorkSpace supports \"Paste-Only\" clipboard redirect (using Ctrl+Shift+V in your WorkSpace). This means you can copy and paste things from your local workstation to the WorkSpace, but not the other way around.  </li> <li>Your WorkSpace user will not have access as local administrator by default, but the user account is able to install user level libraries and packages.   </li> <li>Pre-installed applications such as FireFox, VSCode, and MySQL WorkBench can be found in the Applications library, which can be opened by clicking \"Show Applications\".  </li> <li>WorkSpaces will shut down after an hour of inactivity.  </li> </ul>"},{"location":"#connecting-to-your-teams-sagemaker-studio","title":"Connecting to your team's SageMaker Studio","text":"<p>SageMaker Studio is a web-based IDE, similar to JupyterLab, that enables you run code on AWS instances. Each team is provided a SageMaker domain, and individual users are provided user profiles. Each user profile has an Elastic File Store within their profile to store files. When creating a kernel or running arbitrary code, SageMaker studio will prompt you to create an instance from an image. Instances define the hardware specifications and images define the software specifications. To access SageMaker Studio, we provided you a set-up script that will create a log-in application within your WorkSpace (i.e., <code>open_presigned_domain_url.sh</code>). The instructions below allows you to configure your WorkSpace to generate this log-in application.</p> <p>You should receive two emails containing information about the WorkSpace and SageMaker domain. The SageMaker domain email will look similar to the one show below and contains the information you need to connect to SageMaker. You will need to first set up your WorkSpace before proceeding to connect to SageMaker.</p> <p>Dear User,</p> <p>Below is your SageMaker Studio log-in details. Please contact APL-DTC-Help@jhuapl.edu if you have any questions.</p> <p>AWS Access Key:  <p>AWS Secret Key:  <p>Studio Domain ID:  <p>User Profile:  <p>Follow the steps below to configure your WorkSpaces to connect to your SageMaker Studio. You will only need to configure your SageMaker Studio once. After initial configuration, you can use the generated launch script to reconnect to your SageMaker studio. </p> <ol> <li> <p>Connect to your Ubuntu WorkSpace using the AWS WorkSpace client.</p> </li> <li> <p>Open a terminal window and run the following command to configure your AWS credentials. These credentials are shared by your team and allow you to create pre-signed URLs to your team's SageMaker domain.</p> <p><code>aws configure</code></p> <p>The CLI will then prompt you to input your AWS Access key (i.e., <code>&lt;USER_AWS_ACCESS_KEY&gt;</code>) and secret key (i.e., <code>&lt;USER_AWS_SECRET_KEY&gt;</code>), which can be copied directly from the set-up email. Set the default region to <code>us-east-1</code> and leave the default output format empty. </p> </li> <li> <p>Each WorkSpace comes pre-loaded with a set-up script named <code>dtc-setup.sh</code>. This script creates a launch script, <code>open_presigned_domain_url.sh</code>, that when ran will generate an authenticated URL and open it on the default browser. To use the script, open a terminal and run the <code>dtc-setup.sh</code> and replace the arguments with your own values for domain ID and user profile name from the set-up email:</p> <p><code>dtc-setup.sh &lt;TEAM_DOMAIN_ID&gt; &lt;USER_PROFILE_NAME&gt;</code></p> <p><p></p></p> <p>You'll know the script ran successfully when there is a new file on your desktop named <code>open_presigned_domain_url.sh</code>. </p> </li> <li> <p>Launch the script directly from the Desktop by right-clicking it and clicking \"Run as Program\". Alternatively, you can run it from the terminal.</p> </li> </ol> <p></p> <p>Running the launch script should open a new tab or window on your browser and load SageMaker Studio default page. </p> <p></p> <p>A few important things to consider when using SageMaker instances:      </p> <ul> <li>DARPA provided each team a budget to maintain the team\u2019s infrastructure, perform analysis, and develop models. Please use your resources judiciously and efficiently!   </li> <li>SageMaker instances will continually accrue expenses so long as they are active. We strongly advise that you shut down any unused or idle instances to avoid accruing unwanted costs. See SageMaker Instances for available instances and their associated rates. These rates are subject to change.   </li> <li>APL will be sending weekly cost reports via email to inform you of the status of your weekly/total cost accrual and resource usage statistics.  </li> </ul>"},{"location":"#quick-start-sagemaker-studio","title":"Quick Start SageMaker Studio","text":"<p>Using SageMaker Studio tool, you will be able to access GPU resources to train and evaluate your models. We recommend that you go through the AWS official documentation to familiarize yourself with the tools available to you.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<ol> <li> <p>Once you have SageMaker Studio loaded on your browser, select whether you want to create a JupyterLab space or a Code Editor space. Both types of spaces will provide access to a Python environment and a terminal.  </p> <p><p></p></p> </li> <li> <p>Configure your environment by selecting your SageMaker instance type and storage options. </p> <p><p></p></p> <p>Select your SageMaker instance: <p></p></p> </li> <li> <p>Once satisfied with the configured options (these can be updated from this same page in the future), select \"Run Space\" to start environment.</p> <p>The environment will take a few minutes to start up. Click the \"JupyterLab\" (or Code Editor if that is the space type you chose) icon from the left navigation bar, your new space should be in the given list. Wait until your space status has changed from \"Starting\" to \"Running\" before opening your space. <p></p> </p> </li> <li> <p>Once you are able to open the environment the launch page will load where you can choose what Python environment to open.     <p></p></p> <p>Selecting any of the Notebook types will create a \"Untitled.ipynb\" file and begin instantiating the kernel. This instantiation process may take a while as SageMaker is provisioning your environment with the necessary resources. You may encounter this notification: <p></p></p> </li> <li> <p>Once the instantiation process is complete and you see this screen below, you may begin developing!</p> <p><p></p></p> </li> </ol> <p>To shutdown a SageMaker instance, click on the \"Running Instances\" icon (left side of the dashboard).  It is recommended to turn off spaces that are not in use to prevent accruing unnecessary costs.</p> <p></p>"},{"location":"#transferring-data-to-and-from-s3-buckets","title":"Transferring data to and from S3 buckets","text":"<p>Each user has access to 3 different storage types:</p> <ol> <li>SageMaker Studio Elastic File System (EFS) for user private storage.</li> <li>Team Scratch Bucket (S3 bucket) (<code>dtc-scratch-{team_name}</code>) for sharing with teams.</li> <li>Read-only Training Dataset Bucket (S3 bucket) (<code>dtc-training-data</code>) for storing the official training dataset.</li> </ol> <p>You can access your private storage within SageMaker Studio. To transfer files from the S3 buckets (i.e., Team Scratch and Training Dataset Bucket) you can either do so in your (1) terminal or (2) notebooks:</p>"},{"location":"#transferring-files-using-terminal","title":"Transferring files using terminal:","text":"<ol> <li> <p>From within a JupyterLab environment, open a terminal. (This can also be done in Code Editor.)  </p> <p><p></p></p> <p>In the terminal, you may use the AWS CLI S3 to run commands (e.g., <code>cp</code>, <code>ls</code>, <code>rm</code>, etc.).</p> </li> <li> <p>To copy (<code>cp</code>) files from the scratch bucket to the into your (EFS) from you can use the command <code>aws s3 cp s3://dtc-scratch-{team_name}/path/to/file .</code>. To copy files into the scratch bucket from your EFS storage, you may use <code>aws s3 cp &lt;filename&gt; s3://dtc-scratch-{team_name}/path/</code>.</p> </li> </ol>"},{"location":"#transferring-files-using-notebooks","title":"Transferring files using notebooks:","text":"<p>You man transfer files between storage containers using an array of python packages (e.g., <code>S3Fs</code>, <code>boto3</code>, etc.)</p> <ol> <li>Create a notebook.     </li> <li>Update \"team_name\" to be your team's tag.      </li> <li>Create a test.txt file in the same directory as your notebook.  </li> <li>In a cell, run:</li> </ol> <pre><code>import s3fs\nfs = s3fs.S3FileSystem()  \n\nteam_name = \"\"\n\n# Upload files to S3 bucket\nfs.upload(\"test.txt\", f's3://dtc-scratch-{team_name}/test.txt')\n\n# Download files to EFS\nfs.download(f's3://dtc-scratch-{team_name}/test.txt', \"test.txt\")\n\n# To List 5 files in your team scratch bucket\nprint(fs.ls(f's3://dtc-scratch-{team_name}/')[:5])\n\n# Open files directly\nwith fs.open(f's3://dtc-scratch-{team_name}/test.txt') as f:\n    print(f.read())\n</code></pre>"},{"location":"cobalt/","title":"Getting Started with BluelightAI Cobalt","text":""},{"location":"cobalt/#what-is-cobalt","title":"What is Cobalt?","text":"<p>Cobalt is a toolbox that helps you diagnose and repair problems with AI models. It uses Topological Data Analysis (TDA) to uncover patterns in the ways models transform their input data into output data. You can use Cobalt with any type of model or data, as long as you can produce vector embeddings of that data. Cobalt uses these to build representations of your data and reveal ways the model fails.</p>"},{"location":"cobalt/#how-can-i-access-cobalt-within-the-dtc-sagemaker-environment","title":"How can I access Cobalt within the DTC SageMaker environment?","text":"<p>Cobalt is pre-installed into a dedicated <code>conda</code> environment, <code>cobalt-env</code>, as part of the default SageMaker Lifecycle Configuration (LCC) script. Run <code>conda env list</code> from the SageMaker terminal to verify that the environment has been installed. If the environment is not available, you may need to restart your SageMaker space, making sure it runs with the Lifecycle Configuration script containing the text \"cobalt\"; this script is what performs the installation and setup. It will not disturb your existing <code>conda</code> environments.</p> <p>You can access this environment within JupyterLab Notebooks by selecting \u201cPython 3 (cobalt-env)\u201d from the Select Kernel dropdown, located at the top-right of each JupyterLab Notebook.</p>"},{"location":"cobalt/#how-can-i-learn-more-about-using-cobalt","title":"How can I learn more about using Cobalt?","text":"<p>We recommend the example notebooks as a great place to start. These are placed at <code>~/.config/cobalt/cobalt-notebooks.tar.gz</code> by the LCC script mentioned above.</p> <p>Please refer to the Cobalt documentation for a complete guide. The Concept Overview section is a good starting point to gain a high-level understanding of Cobalt use cases and concepts.</p>"},{"location":"common_issues/","title":"Common Issues and Troubleshooting","text":"<p>Below we describe common issues and troubleshooting steps for AWS WorkSpaces and SageMaker Studio. Please contact the JHU APL team (APL-DTC-Help@jhuapl.edu) if you have any questions or need further troubleshooting.  </p>"},{"location":"common_issues/#workspace","title":"WorkSpace","text":"<ol> <li> <p>\"Password Expired\" Passwords can be reset via the \"Forgot Password\" link on the WorkSpaces client. Depending on your client version and machine OS, you may need to fully log-out to see the \"Forgot Password\" link near the bottom of the view. Refer to this forum post for more instructions. In some cases, browser cache can affect the reset password screen. If you encounter an error in reseting your password after clicking \"Forgot Password\", try using another browser or an incognito/private browser window that does not use the pre-existing browser cache.  </p> </li> <li> <p>\"Unable to connect to Network\" Connection issues to WorkSpaces are typically a result of an external firewall or network restriction blocking the WorkSpaces port. This AWS document describes the ports that need to be available for the WorkSpaces to properly stream to the client. If the issues still persists, follow the logging steps described here to collect low-level system logs. Send these logs to the APL team and we will help debug and troubleshoot. </p> </li> <li> <p>Sudo Access and Installing Applications Participants are unable to perform \"sudo\" commands on their WorkSpace, making it difficult or impossible to install new libraries or programs via <code>apt-get</code> or other standard package managers. While we don't recommend using the WorkSpace instance for any development or model training, we are happy to modify your team's base image with any additional tools or software that you'd like to have, just email the JHU APL team. Keep in mind that the WorkSpace is mainly there to provide way to stream SageMaker securely, and offers little in terms of compute resources (4 Cores, 16 GB RAM, no GPU). </p> </li> </ol>"},{"location":"common_issues/#sagemaker","title":"SageMaker","text":"<ol> <li> <p>Managing Environment Refer to this link for best-practices and tutorials on how to manage conda environments within SageMaker. When executing code in a notebook or script, SageMaker will prompt you to start an \"instance\". We recommend you pick an instance that matches the requirements for the code to run successfully. (i.e. pick a high RAM instance if your code needs a lot of memory, or a GPU instance if your code needs CUDA.) Refer to SageMaker Instances for a list of instance types and their specifications. Make sure to shutdown instances when you are done using them via the instance management panel in the SageMaker UI. </p> </li> <li> <p>Broken Packages/Images Sometimes the default AWS images provided in SageMaker are updated and package versions are changed or broken. This link contains the list of all AWS pre-built images. If the pre-built images are not working for your particular use-case, e-mail us to set up a custom image built to your specifications via Dockerfile. </p> </li> </ol>"},{"location":"configure_codecommit/","title":"Accessing CodeCommit Credentials and Configuring Git for Your Team","text":"<p>This guide outlines the steps for team members to obtain AWS CodeCommit credentials and set up Git in your SageMaker Studio for interacting with your team's CodeCommit repository. If you require further assistance or experience any difficulties during this process, do not hesitate to contact us at APL-DTC-Help@jhuapl.edu for support.</p>"},{"location":"configure_codecommit/#obtaining-git-codecommit-credentials","title":"Obtaining Git CodeCommit Credentials","text":"<p>The AWS Secrets Manager securely stores your team's CodeCommit credentials. To access your credentials, you can use the AWS Command Line Interface (CLI) from your SageMaker (or WorkSpace) terminal. It's important to note that access is restricted to your own team's credentials, ensuring each team member can only retrieve their respective credentials. However, this setup also ensures that every team member has the capability to securely access their team's CodeCommit credentials.</p> <p>To retrieve your CodeCommit credentials, replace {team_tag} with your actual team name and execute the following command:</p> <pre><code>aws secretsmanager get-secret-value --secret-id {team_tag}/codecommit\n</code></pre> <p>Executing this command will produce a JSON object containing your credentials. It should return an output with the following format: <pre><code>{\n    \"ARN\": \"arn:aws:secretsmanager:us-east-2:123456789012:secret:teamname/codecommit-a1b2c3\",\n    \"Name\": \"teamname/codecommit\",\n    \"VersionId\": \"a1b2c3d4-5678-90ab-cdef-EXAMPLE11111\",\n    \"SecretString\": \"{\\\"GitUsername\\\":\\\"dtc-teamname-admin-at-5589909584939\\\",\\\"password\\\":\\\"EXAMPLE-PASSWORD\\\"}\",\n    \"VersionStages\": [\n        \"AWSCURRENT\"\n    ],\n    \"CreatedDate\": \"2024-03-08T17:40:33.06400+00:00\"\n}  \n</code></pre></p> <p>To locate your username and password, search for the <code>SecretString</code> field within the JSON output. Note: The GitUsername and password are surrounded by escaped quotes (e.g. <code>\\\"</code>).  Be sure to only copy the characters inside the escaped quotations. Including the escape characters will cause a 403 error.</p> <p>Should you encounter the error message No such file or directory: 'less', this issue can be resolved by installing the less package. Run the following command to install less:</p> <pre><code>sudo apt-get install less\n</code></pre>"},{"location":"configure_codecommit/#configuring-git","title":"Configuring Git","text":"<p>We recommend configuring your Git name, email and cache settings before cloning. </p> <p>First, configure Git with your name and email. Replace Your Name and your_email@example.com with your actual name and email:</p> <pre><code>git config --global user.name \"Your Name\"\ngit config --global user.email \"your_email@example.com\"\n</code></pre> <p>To avoid entering your credentials every time you interact with your CodeCommit repository, you can use Git's credential caching feature. First, ensure you have the AWS CLI installed and configured on your machine.</p> <p>Then, execute the following command to cache your credentials for a specified time (in seconds). For example, to cache credentials for 2 hours (7200 seconds):</p> <pre><code>git config --global credential.helper 'cache --timeout=7200'\n</code></pre>"},{"location":"configure_codecommit/#repository-access","title":"Repository Access","text":"<p>All teams are provided one repository. Contact us if you'd like to set up more repositories for your team. You should be able to access your team's repository outside AWS. You can use the same CodeCommit credentials.</p>"},{"location":"configure_codecommit/#your-teams-repository-name","title":"Your Team's Repository Name","text":"<p>Your CodeCommit repository is set up under the name <code>{team_tag}</code>, where <code>{team_tag}</code> should be replaced with your team tag.</p> <p>You can clone it with the following command: </p> <pre><code>git clone https://git-codecommit.us-east-1.amazonaws.com/v1/repos/{team_tag}\n</code></pre> <p>When you first push to or pull from your CodeCommit repository, Git will prompt you for your username and password. Enter the credentials obtained from AWS Secrets Manager.</p> <p>Note: For CodeEditor, you will be prompted to use your provided Git username and password at the top of the browser. </p>"},{"location":"configure_codecommit/#aws-dtc-codecommit-repository-management","title":"AWS DTC CodeCommit Repository Management","text":"<p>This guide provides steps to create and manage AWS CodeCommit repositories in the DTC AWS account using the AWS Command Line Interface (CLI). Participants may use their DTC credentials to create CodeCommit repositories on their local machines, SageMaker, or WorkSpace. New repositories have two requirements:</p> <ul> <li>The name of the repository must be prefixed by your team's tag separated by a dash. </li> <li>The repository must be tagged with key <code>dtc-team</code> set to your team's tag. </li> </ul> <p>Example  Assuming my team was <code>apl-lima</code>, I can create a repository called <code>apl-lima-lib</code> with the resource tag <code>dtc-team=apl-lima</code>.  I would NOT be able to create a repository with name <code>apl-foxtrot</code> or <code>apl-limaScratch</code> since they do not match the <code>{team-tag}-</code> pattern. </p>"},{"location":"configure_codecommit/#creating-a-repository-with-specific-name-prefix-and-tag","title":"Creating a Repository with Specific Name Prefix and Tag","text":"<p>To create a repository that has a team prefix in the name and includes a tag, use the following command:</p> <pre><code>aws codecommit create-repository --repository-name &lt;team-tag&gt;-&lt;repo-name&gt; --repository-description \"Repository for project\" --tags 'dtc-team=&lt;team-tag&gt;'\n</code></pre>"},{"location":"configure_codecommit/#parameters","title":"Parameters:","text":"<ul> <li><code>--repository-name</code>: Name of the repository to create. Must include the required prefix, e.g., \"dtc-\".</li> <li><code>--repository-description</code>: A description for the repository.</li> <li><code>--tags</code>: Key-value pairs to tag the repository.</li> </ul>"},{"location":"configure_codecommit/#common-codecommit-commands","title":"Common CodeCommit Commands","text":""},{"location":"configure_codecommit/#get-repository-details","title":"Get Repository Details","text":"<p>To get detailed information about a specific repository:</p> <pre><code>aws codecommit get-repository --repository-name &lt;team-tag&gt;-&lt;repo-name&gt; \n</code></pre>"},{"location":"configure_codecommit/#delete-a-repository","title":"Delete a Repository","text":"<p>To delete a repository:</p> <pre><code>aws codecommit delete-repository --repository-name &lt;team-tag&gt;-&lt;repo-name&gt; \n</code></pre>"},{"location":"configure_codecommit/#list-repositories","title":"List Repositories","text":"<p>We do not provide permissions to users to list repositories. If you would like to get a report or status of one or more of your teams repositories, please contact APL-DTC-Help@jhuapl.edu.</p>"},{"location":"configure_codecommit/#more-info","title":"More info","text":"<p>More info about CodeCommit available in the official AWS Docs.</p>"},{"location":"creating_custom_images/","title":"Creating custom Docker Images to use in SageMaker","text":"<p>This guide walks you through the process of pushing a custom Docker image to an Amazon Elastic Container Registry (ECR) repository named dtc-{team-prefix} and subsequently using this image in AWS SageMaker Studio for your data science and machine learning projects.</p> <p>Prerequisites - AWS CLI installed and configured on your machine. - Docker installed on your machine. - Team IAM Credentials (AWS Access keys) - Knowledge of your team's prefix to replace {team-prefix} in the repository name.</p>"},{"location":"creating_custom_images/#finding-your-teams-repository","title":"Finding your team's repository","text":"<p>Each team has a default repository created for them under the name <code>dtc-{team-prefix}</code>. To check the status of your repository, you can use the AWS CLI.</p> <pre><code>aws ecr describe-repositories --repository-name dtc-&lt;team-name&gt;\n</code></pre> <p>Only your team and DTC Admins have the permissions to view your ECR repository. Contact admins if you would like additional repositories. </p>"},{"location":"creating_custom_images/#authenticate-docker-of-your-ecr-repository","title":"Authenticate Docker of Your ECR Repository","text":"<p>Before pushing images to ECR, you must authenticate Docker to the ECR registry. Run the following command directly to authenticate your terminal to push to your ECR repository. </p> <pre><code>aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 552707247569.dkr.ecr.us-east-1.amazonaws.com\n</code></pre>"},{"location":"creating_custom_images/#pushing-your-docker-image","title":"Pushing your Docker Image","text":"<p>Navigate to the directory containing your Dockerfile and run the following command, replacing {image-name} with your desired image name. If not specified, it will default to <code>latest</code>.</p> <pre><code>docker build --network sagemaker -t dtc-{team-prefix}:{image-name} .\n</code></pre> <p>Tag the image to the ECR repository URL. </p> <pre><code>docker tag dtc-{team-prefix}:{image-name} 552707247569.dkr.ecr.us-east-1.amazonaws.com/dtc-{team-prefix}:{image-name}\n</code></pre> <p>Finally, push the image to your ECR repository.</p> <pre><code>docker push 552707247569.dkr.ecr.us-east-1.amazonaws.com/dtc-{team-prefix}:{image-name}\n</code></pre>"},{"location":"creating_custom_images/#attaching-your-image-to-sagemaker-studio","title":"Attaching your image to SageMaker Studio","text":"<p>To attach the image to your SageMaker studio domain, follow the CLI-specific instructions provided in this AWS reference document. </p> <p>Once you reach the final step of creating the App Image Config, send an email to APL-DTC-Help@jhuapl.edu with your image name, app config name and team name for an admin to add it to your domain. </p> <p>Note: You do not need to provide an execution role ARN when creating the image or image configurations through AWS. The execution role should be an optional argument. </p>"},{"location":"importing_data/","title":"Using the S3 Bucket \"dtc-import\" for Data Transfer","text":"<p>This guide will go over how to use the S3 bucket \"dtc-import\" for transferring data into the DTC Virtual Private Cloud (VPC). This document is intended for DTC participants who need to upload data securely and efficiently to our AWS environment. The <code>dtc-import</code> bucket has been set up with specific prefixes for each team. </p>"},{"location":"importing_data/#prerequisites","title":"Prerequisites","text":"<ul> <li>AWS CLI installed on your machine. Download AWS CLI</li> <li>IAM Credentials for your team.    </li> <li>Knowledge of your specific team's prefix within the <code>dtc-import</code> bucket.</li> </ul>"},{"location":"importing_data/#finding-your-teams-prefix","title":"Finding Your Team's Prefix","text":"<p>Each team has been assigned a unique prefix within the <code>dtc-import</code> bucket. Your team's prefix is structured as follows: <code>team-tag/</code>. Replace <code>team-tag</code> with your actual tag. Your team tag is typically the first part of your WorkSpace or SageMaker username, before the hyphen. For example, if your WorkSpace username is <code>apl-smithj</code>, your team tag is <code>apl</code>.   </p>"},{"location":"importing_data/#uploading-files-to-your-teams-prefix","title":"Uploading Files to Your Team's Prefix","text":"<p>To upload files from your external network to your team's prefix in the <code>dtc-import</code> bucket, follow these steps:</p> <ol> <li> <p>Open your terminal or command prompt.</p> </li> <li> <p>Configure the AWS CLI with your credentials.    Run <code>aws configure</code> and follow the prompts to input your AWS Access Key ID, Secret Access Key, region, and output format. Region should be set to <code>us-east-1</code> and output format could be left blank.</p> </li> <li> <p>Use the AWS CLI to upload files.    To upload a file to the S3 bucket, use the following command, replacing <code>path/to/your/file</code> with the path to the file you wish to upload and <code>team-tag</code> with your actual team tag.</p> <pre><code>aws s3 cp path/to/your/file s3://dtc-import/{team-tag}/\n</code></pre> </li> </ol> <p>For example, if your team tag is <code>jhu</code> and you're uploading <code>data.csv</code> from your desktop, the command would be:</p> <pre><code>aws s3 cp ~/Desktop/data.csv s3://dtc-import/jhu/data.csv \n</code></pre>"},{"location":"importing_data/#downloading-files-from-your-teams-prefix","title":"Downloading Files from Your Team's Prefix","text":"<p>To download files from your team's prefix to a machine inside your WorkSpace or SageMaker Studio environment, use the following AWS CLI command. WorkSpace and SageMaker should already have awscli pre-installed. </p> <pre><code>aws s3 cp s3://dtc-import/{team-tag}/filename /local/path \n</code></pre> <p>Replace /local/path with the path where you want to download the file on your local machine, team-tag with your team's tag, and filename with the name of the file you're downloading. Only members of your team are able to copy data from your team prefix. </p> <p>Additionally, if you want to list the contents of your prefix, you can use the following command. (could also be ran outside of the VPC). </p> <pre><code>aws s3 ls s3://dtc-import/{team-tag}/\n</code></pre>"},{"location":"importing_data/#best-practices","title":"Best Practices","text":"<ul> <li>Organize your data: Use sub-prefixes under your team's prefix to organize data further, e.g., team-tag/project-name/.</li> <li>Clean up: Regularly review and delete old or unnecessary files to keep your team's prefix organized and minimize storage costs.</li> </ul>"},{"location":"metrics_guide/","title":"Metrics Guide","text":"<p>The metrics scripts included in the <code>client-shell</code> output the following files:</p> <ul> <li> <p>Ground Truth CSV</p> </li> <li> <p>Response JSON</p> </li> <li> <p>Metrics JSON</p> </li> <li> <p>Detailed Metrics CSV</p> </li> <li> <p>Threshold Metrics CSV</p> </li> </ul>"},{"location":"metrics_guide/#ground-truth-csv","title":"Ground Truth CSV","text":"<p>The ground truth CSV contains the relevant ground truth LSIs for each segment of patient data. It uses the following file name convention: <code>&lt;PHASE&gt;_&lt;EVENT&gt;_gt_&lt;DATE&gt;.csv</code>.</p> <p>The ground truth CSV has the following fields, indicated by a header row in the first line.</p> <p>Table 1: Ground Truth CSV Fields</p> Field Definition studyid Case identifier. source Case dataset source: <code>umb</code> or <code>upitt</code>. segment_num Segment index within the case. segment_start_time Start time in seconds for the segment, relative to start of case. segment_end_time Stop time in seconds for the segment, relative to start of case. lsi_group The LSI category. max_lsi_time Time of last LSI for given LSI group, relative to start of case. gt 1 if the LSI occurred during the segment's prediction window, 0 otherwise. time_since_adm_sec Time elapsed from hospital admission to <code>segment_stop_time</code>"},{"location":"metrics_guide/#response-json","title":"Response JSON","text":"<p>The response JSON contains the client model\u2019s prediction responses for each segment of patient data, along with timestamps for when prediction message was sent and received by the evaluation server. It uses the following file name convention: <code>&lt;PHASE&gt;_&lt;EVENT&gt;_responses_&lt;TEAM&gt;-&lt;RUNTYPE&gt;_&lt;DATE&gt;.json</code>.</p> <p>The response JSON has the following format: <pre><code>{\n    \"team_name\": &lt;string&gt;,\n    \"event\": &lt;string&gt;,\n    \"evaluation_date\": &lt;date&gt;,\n    \"responses\": [\n        {\n            \"message_sent_time\": &lt;double&gt;,\n            \"message_received_time\": &lt;double&gt;,\n            \"case_id\": &lt;string&gt;,\n            \"studyid\": &lt;string&gt;,\n            \"segment_num\": &lt;double&gt;,\n            \"segment_id\": &lt;string&gt;,\n            \"model_predictions\": &lt;dict&gt;,\n            \"cumulative_runtime_sec\": &lt;double&gt;,\n            \"run_id\": &lt;GUID&gt;,\n            \"end_of_case\": &lt;bool&gt;,\n            \"raw_response\": [&lt;string&gt;, &lt;string&gt;, ...],\n            \"error\": &lt;string&gt;,\n            \"embeddings\": &lt;dict&gt;\n        },\n        ...\n    ]\n}\n</code></pre> Table 2: Response JSON Fields</p> Field Definition team_name Team name. event Event name. evaluation_date Date of evaluation run. responses List of responses for all segments. message_sent_time UNIX timestamp in seconds when the server\u2019s prediction message was sent to the client for the segment. message_received_time UNIX timestamp in seconds when the client\u2019s prediction message was received by the server for the segment. case_id Unique case id. studyid Case identifier. segment_num Segment index within the case. segment_id Unique <code>segment id.</code> See inventory.csv file for ordering. model_predictions Dictionary containing LSI confidence scores for each LSI group received from the client. cumulative_runtime_sec Cumulative runtime over the entire evaluation in seconds for the segment. run_id GUID for the evaluation run for the segment. end_of_case Boolean value indicating whether the segment is the last segment of the case. raw_response If error present, original client response for the segment. error Error message from the server, if present. embeddings Optional dictionary containing  embeddings at different levels of internal data analysis."},{"location":"metrics_guide/#metrics-json","title":"Metrics JSON","text":"<p>The metrics JSON contains the client model performance metrics calculated for each case: the Mean Squared Correct (MSC). It uses the following file name convention: <code>&lt;PHASE&gt;_&lt;EVENT&gt;_metrics_&lt;TEAM&gt;-&lt;RUNTYPE&gt;_&lt;DATE&gt;.json</code>.</p> <p>The metrics JSON has the following format: <pre><code>{\n    \"team_name\": &lt;string&gt;,\n    \"run_type\": &lt;string&gt;,\n    \"event\": &lt;string&gt;,\n    \"evaluation_date\": &lt;date&gt;,\n    \"response_file_name\": &lt;string&gt;,\n    \"event_normalized_msc\": &lt;double&gt;,\n    \"run_normalized_msc\": &lt;double&gt;,\n    \"avg_specificity_sensitivity_benchmark\": {\n        \"benchmark\": &lt;dict&gt;,\n        \"surpassed\": &lt;bool&gt;\n    },\n    \"segment_weights\": &lt;dict&gt;,\n    \"sensitivity_specificity_by_LSI\": [\n        {\n            \"lsi_group\": &lt;string&gt;,\n            \"threshold\": &lt;double&gt;,\n            \"sensitivity\": &lt;double&gt;,\n            \"specificity\": &lt;double&gt;,\n            \"balanced_accuracy\": &lt;double&gt;\n        },\n        ...\n    ],\n    \"metrics_by_case\": [\n        {\n            \"studyid\": &lt;string&gt;,\n            \"case_normalized_msc\": &lt;double&gt;,\n            \"runtime\": &lt;double&gt;,\n            \"source\": &lt;string&gt;\n            \"errors\": [\n                {\n                    \"segment_id\": &lt;string&gt;,\n                    \"error\": &lt;string&gt;\n                },\n                ...\n            ]\n        },\n        ...\n    ]\n}\n</code></pre></p> <p>Table 3: Metrics JSON Fields</p> Field Definition team_name Team name. run_type Run type: <code>B</code> for Basic EHR, <code>E</code> for Expanded EHR, <code>V</code> for Vitals Only. event Event name. evaluation_date Date of evaluation run. response_file_name Response JSON used to generate this Metrics JSON. event_normalized_msc Normalized MSC for entire evaluation. run_normalized_msc Normalized MSC for single run. avg_specificity_sensitivity_benchmark Benchmark criteria and passing result. benchmark Dictionary of LSI group and minimum avg sensitivity/specificity score. surpassed True if run passed all LSI benchmarks, False otherwise. segment_weights Dictionary of weights by source, LSI group, and ground truth value. sensitivity_specificity_by_LSI List of specificty and sensitivity with highest balanced accuracy per LSI group. lsi_group The LSI category. threshold Threshold for max balanced accuracy. sensitivity Sensitivity at threshold. specificity Specificity at threshold. balanced_accuracy Average of specificity and sensitivity. metrics_by_case List of metrics calculated for each case. studyid Case identifier. case_normalized_msc Normalized MSC calculated for case. runtime Cumulative runtime in seconds at the end of the case. errors Errors found by the server during the case. segment_id Segment id where error occurred. error Error message from the server."},{"location":"metrics_guide/#detailed-metrics-csv","title":"Detailed Metrics CSV","text":"<p>The detailed metrics CSV contains the client model performance metrics calculated for each segment and LSI group. It uses the following file name convention: <code>&lt;PHASE&gt;_&lt;EVENT&gt;_detailed-metrics_&lt;TEAM&gt;-&lt;RUNTYPE&gt;_&lt;DATE&gt;.csv</code>.</p> <p>Table 4: Detailed Metrics CSV Fields</p> Field Definition studyid Case identifier. source Case dataset source: <code>umb</code> or <code>upitt</code>. segment_num Segment index within the case. segment_start_time Start time in seconds for the segment, relative to start of case. segment_end_time Stop time in seconds for the segment, relative to start of case. lsi_group The LSI category. max_lsi_time Time of last LSI for given LSI group, relative to start of case. gt 1 if the LSI occurrs within the segment's prediction window, 0 otherwise. time_since_adm_sec Time elapsed from hospital admission to <code>segment_stop_time</code> ignore_segment 0 if segment prediction contributes to MSC, 1 if ignored due to minimum prediction horizon or minimum lead time. segment_weight Unnormalized weight based on inverse frequency of segments with same source and LSI ground truth, 0 if this prediction is within minimum lead time or outside of prediction horizon. case_normalized_segment_weight <code>segment_weight</code> divided by sum of <code>segment_weight</code>s over case. run_normalized_segment_weight <code>segment_weight</code> divided by sum of <code>segment_weight</code>s over run. event_normalized_segment_weight <code>run_normalized_segment_weight</code> multiplied by run weight. model_prediction LSI confidence score for segment. cumulative_runtime_sec Cumulative runtime in seconds at the end of the segment. error Errors found by the server during the segment. unweighted_msc Raw Mean Squared Correct (MSC) value for segment and LSI group. case_normalized_msc <code>unweighted_msc</code> *  <code>case_normalized_segment_weight</code> run_normalized_msc <code>unweighted_msc</code> *  <code>run_normalized_segment_weight</code> event_normalized_msc <code>unweighted_msc</code> *  <code>event_normalized_segment_weight</code>"},{"location":"metrics_guide/#threshold-metrics-csv","title":"Threshold Metrics CSV","text":"<p>The threshold metrics CSV contains the client model binary classification metrics calculated at different thresholds for each LSI group. It uses the following file name convention: <code>&lt;PHASE&gt;_&lt;EVENT&gt;_threshold-metrics_&lt;TEAM&gt;-&lt;RUNTYPE&gt;_&lt;DATE&gt;.csv</code>.</p> <p>Table 4: Threshold Metrics CSV Fields</p> Field Definition lsi_group The LSI category. threshold Cut-off value to classify a prediction as positive or negative sensitivity True positive rate; proportion of actual positives correctly identified specificity True negative rate; proportion of actual negatives correctly identified PPV Positive Predictive Value; proportion of predicted positives that are correct NPV Negative Predictive Value; proportion of predicted negatives that are correct TP True Positives; segments correctly predicted as positive TN True Negatives; segments correctly predicted as negative FP False Positives; segments incorrectly predicted as positive FN False Negatives; segments incorrectly predicted as negative balanced_accuracy Average of sensitivity and specificity F1 Harmonic mean of precision (PPV) and sensitivity"},{"location":"running_client_shell/","title":"Client Container Shell","text":""},{"location":"running_client_shell/#overview","title":"Overview","text":"<p>This is the README for the Client Container Shell and supporting materials for teams participating in the DARPA Triage Challenge Data Competition. The Client Container Shell can be used to prepare submissions for the workshop and challenge events in accordance with the Data Competition ICD (available at https://triagechallenge.darpa.mil).</p>"},{"location":"running_client_shell/#minimum-requirements","title":"Minimum Requirements","text":"<ul> <li>Python 3.10 or newer*</li> <li>Docker* (See Configuring Docker)</li> <li>Model that implements methods in provided <code>DTC_BaseModel</code> base class: <code>predict()</code>, <code>acknowledge()</code>, <code>cleanup()</code>, and <code>timed_out()</code> (See example in template_model.py )    </li> </ul> <p>*Note: these installations should already be available when working from within the SageMaker environment.</p>"},{"location":"running_client_shell/#quick-start","title":"Quick Start","text":"<ol> <li>Clone client-shell repository from CodeCommit  <code>git clone https://git-codecommit.us-east-1.amazonaws.com/v1/repos/client-shell</code> </li> <li>Configure model according to Client Shell (See Configuring your Model)</li> <li>Download and start RabbitMQ Server (See Starting the RabbitMQ server)</li> <li>Run the client using one of two options:   <ul> <li>Run as Docker container (See Running the Client with Docker)  </li> <li>Run locally within AWS WorkSpace (See Running the Client locally)   </li> </ul> </li> <li>Test connection between client and server using messaging stub (See Passing Messages to the Client).</li> <li>Evaluate client using <code>dtc-evaluator</code> and run metrics on output (See Evaluating Your Model in SageMaker).</li> </ol>"},{"location":"running_client_shell/#configuring-your-model","title":"Configuring your Model","text":"<p>Your model must inherit from <code>dtc_messaging.model.DTC_BaseModel</code> in order to interface with the evaluator. The model class must override five methods: <code>predict()</code>, <code>acknowledge()</code>, <code>cleanup()</code>, <code>timed_out()</code>, <code>error()</code>.  Each method above is a callback in response to receipt of one of the message types (MessageType) listed below:</p> <ul> <li><code>PREDICT_MESSAGE</code>: Provides new patient data and requests LSI prediction by calling <code>predict()</code> in the model.</li> <li><code>ACKNOWLEDGE_MESSAGE</code>: Acknowledges receipt of prediction by calling <code>acknowledge()</code> in the model.</li> <li><code>CLEANUP_MESSAGE</code>: Indicates when the processing for the current patient case is complete by calling <code>cleanup()</code> in the model.</li> <li><code>TIMED_OUT_MESSAGE</code>: Indicates the model has timed out during the current prediction request by calling <code>timed_out()</code> in the model.</li> <li><code>ERROR_MESSAGE</code>: Contains error message from the evaluation server.</li> </ul> <p>In addition, there is a <code>CONNECTION_MESSAGE</code> that establishes initial connection between server and model, which is handled by the model base class. As a simple example implementation of the methods listed above, please see the provided template_model.py.</p>"},{"location":"running_client_shell/#starting-the-rabbitmq-server","title":"Starting the RabbitMQ server","text":"<p>To start a RabbitMQ server with the management plugin enabled, run the following commands in your terminal:</p> <p><code>aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 552707247569.dkr.ecr.us-east-1.amazonaws.com</code></p> <p><code>docker run -d --network sagemaker --rm  552707247569.dkr.ecr.us-east-1.amazonaws.com/dtc-rabbitmq:latest</code></p> <p>RabbitMQ will automatically reserve and map ports <code>15672</code> and <code>5672</code> on the host to ports <code>15672</code> and <code>5672</code> in the server container, respectively. These ports are used by the RabbitMQ server.</p>"},{"location":"running_client_shell/#running-the-client-with-docker","title":"Running the Client with Docker","text":""},{"location":"running_client_shell/#building-with-docker-image","title":"Building with Docker Image","text":"<p>To containerize your model, start by authenticating to be able to pull the <code>dtc-base-image</code></p> <p><code>aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 552707247569.dkr.ecr.us-east-1.amazonaws.com</code></p> <p>Build your docker image with the following command:</p> <p><code>docker build --network sagemaker -t dtc-&lt;TEAM_NAME&gt;:&lt;TAG&gt; .</code></p> <p>This command builds the Docker based on the Dockerfile provided. By default, the client-shell Dockerfile builds itself off of  <code>dtc-base-image:latest</code> which uses GPU. See the below Base Images section, to substitute for a cpu-only base image. Both images include the <code>dtc_messaging</code> python package used to interface with the official evaluation server, and <code>awscli</code> to access available AWS resources provisioned to your team.</p>"},{"location":"running_client_shell/#base-images","title":"Base Images","text":"<p>There are two base images available for your use in the AWS ECR: - dtc-base-image:latest  - dtc-base-image-cpu:latest  </p> <p><code>dtc-base-image:latest</code> is configured for teams whose models require GPU and is built off of <code>nvidia/cuda:12.3.2-cudnn9-devel-ubuntu22.04</code>, while <code>dtc-base-image-cpu:latest</code> holds a lighter-weight framework for those models that only run on CPU, and it is built off of <code>ubuntu:22.04</code>.</p> <p>You should always use images tagged <code>latest</code>, however a full history of dtc-base-image versions is available on the ECR. As of date, the following base images exists:</p> Image Name Tags Release dtc-base-image latest, v1-1 May 2024 dtc-base-image-cpu latest, v1-0 June 2024 dtc-base-image v1-0 March 2024 <p>Further, the dtc-base-image repository holds the code used to generate these images. The <code>main</code> branch contains dtc-base-image source code and the <code>cpu-only</code> branch  contains dtc-base-image-cpu source code.</p>"},{"location":"running_client_shell/#running-the-docker-container","title":"Running the Docker Container","text":"<p>After building the image, run the application in a Docker container with the necessary environment variables:</p> <p><code>docker run --network sagemaker -it --rm dtc-&lt;TEAM_NAME&gt;:&lt;TAG&gt;</code></p> <p>This command runs your application in a Docker container, connecting it to an existing RabbitMQ server. The container will be removed automatically after the application exits.</p>"},{"location":"running_client_shell/#running-the-client-locally","title":"Running the Client locally","text":"<p>To run the Client outside docker, you must first install the <code>dtc_messaging</code> package and dependencies in your local environment. Clone the dtc-base-image repo and run the following within the cloned repo:  <code>python -m pip install .</code> </p> <p>The following command will run the client locally with an existing RabbitMQ server: <code>python run_client.py --host localhost --queue rpc_queue</code></p>"},{"location":"running_client_shell/#passing-messages-to-the-client","title":"Passing messages to the Client","text":"<p>The <code>send_message.py</code> script in the <code>stubs/</code> directory can be used to test receipt of sample messages of each MessageType with a running client container. You may run the command:</p> <p><code>python send_message.py --queue rpc_queue -m {CONNECTION_MESSAGE|PREDICT_MESSAGE|ACKNOWLEDGE_MESSAGE|ERROR_MESSAGE|TIMED_OUT_MESSAGE|CLEANUP_MESSAGE}</code></p> <p>to pass a sample message to the client, where a single message type is selected. This should print out the client response message's channel, method, properties, and body data. For example, using the provided <code>ExampleModel</code> class in <code>template_model.py</code> as the model, running <code>python send_message.py -m CONNECTION_MESSAGE</code> would print this response:</p> <pre><code>RESPONSE:\nCHANNEL: &lt;BlockingChannel impl=&lt;Channel number=1 OPEN conn=&lt;SelectConnection OPEN transport=&lt;pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x109060690&gt; params=&lt;ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False&gt;&gt;&gt;&gt;\nMETHOD: &lt;Basic.Deliver(['consumer_tag=ctag1.8851c9e07ab74dfa9a4d64efc4e4df26', 'delivery_tag=1', 'exchange=', 'redelivered=False', 'routing_key=amq.gen-PyPl17EcuEBP5s3LDzgwKA'])&gt;\nPROPERTIES: &lt;BasicProperties(['correlation_id=9c13597d-7aa1-45f6-9e1e-a6734c826328', 'type=CONNECTION_MESSAGE'])&gt;\nBODY: b'{\"response\": {\"response\": \"connected\"}}'\n</code></pre>"},{"location":"running_client_shell/#uploading-docker-image-to-aws-ecr-elastic-container-registry","title":"Uploading docker image to AWS ECR (Elastic Container Registry)","text":"<p>Use the following steps to authenticate and push an image to your team ECR. Note that for submission, this is done automatically within the CodeBuild CI/CD build process for successful builds.</p> <p>Start by retrieving an authentication token and authenticate your Docker client to your registry.</p> <p><code>aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 552707247569.dkr.ecr.us-east-1.amazonaws.com</code></p> <p>Tag your image so you can push the image to this repository:</p> <p><code>docker tag dtc-&lt;TEAM_NAME&gt;:&lt;TAG&gt; 552707247569.dkr.ecr.us-east-1.amazonaws.com/dtc-&lt;TEAM_NAME&gt;:&lt;TAG&gt;</code></p> <p>Run the following command to push this image to your newly created AWS repository:</p> <p><code>docker push 552707247569.dkr.ecr.us-east-1.amazonaws.com/dtc-&lt;TEAM_NAME&gt;:&lt;TAG&gt;</code></p>"},{"location":"running_client_shell/#configuring-docker","title":"Configuring Docker","text":"<p>To check if Docker is installed correctly, run <code>docker version</code> on a system terminal to output API and engine details.  </p> <p>If Docker is not installed properly, you will need to modify your SageMaker app's lifecycle policy. All SageMaker app types (JupyterLab, CodeEditor, Studio Classic) support Docker API access via a proxy docker engine. To access docker in your SageMaker instance, restart or create an instance using the \"install-docker-cobalt-{app-type}\" lifecycle policy.</p> <p>Note: An existing Code Editor or JupyterLab instance will not have Docker installed until you fully stop the instance and re-run with the lifecycle policy. Restarting the instance will not delete any data in the <code>/home/sagemaker-user/</code> directory, but will delete data in other directories. </p>"},{"location":"running_client_shell/#configuring-docker-images-to-access-s3-buckets-using-aws-credentials","title":"Configuring Docker Images to Access S3 Buckets Using AWS Credentials","text":"<p>By default, your credentials will not be passed from SageMaker to your Docker images. As a result, your Docker images is restricted to access your provisioned AWS services. If your submission requires accessing data from your team\u2019s S3 bucket, you may transfer your SageMaker credentials to your Docker image by passing your AWS credentials (i.e., <code>AWS_ACCESS_KEY</code>, <code>AWS_SECRET_ACCESS_KEY</code>) to the Docker image. These access keys should have been emailed to you for your SageMaker account in an email that looks similar to this. Follow these steps:</p> <ol> <li>In your SageMaker terminal, set the environmental variables for <code>KEY</code> and <code>SECRET KEY</code> with your <code>AWS_ACCESS_KEY</code> and <code>AWS_SECRET_ACCESS_KEY</code>, respectively.</li> </ol> <p><pre><code>export KEY=&lt;AWS_ACCESS_KEY&gt;\nexport SECRET_KEY=&lt;AWS_SECRET_KEY&gt;\n</code></pre>     To ensure persistence of these variables, it is recommended you add these two lines to your <code>~/.bashrc</code> file.</p> <ol> <li> <p>Modify your <code>Dockerfile</code> to transfer the target file: Add the following command to your Dockerfile to transfer the target file from S3 to your desired directory within the Docker container. Replace <code>&lt;TEAM_NAME&gt;</code>, <code>&lt;TARGET_FILE&gt;</code>, and <code>&lt;TARGET_DIRECTORY&gt;</code> with your team name, the file you want to transfer, and the target directory inside the Docker container, respectively:     <pre><code>RUN aws s3 cp s3://dtc-scratch-&lt;TEAM_NAME&gt;/&lt;TARGET_FILE&gt; /&lt;TARGET_DIRECTORY&gt;\n</code></pre></p> </li> <li> <p>In the <code>Dockerfile</code> script, you will find the following lines:     <pre><code>ARG KEY\nARG SECRET_KEY\nENV AWS_ACCESS_KEY_ID=$KEY\nENV AWS_SECRET_ACCESS_KEY=$SECRET_KEY\n</code></pre></p> <p>These specify your credentials, as build arguments, to be passed into the Dockerfile. These will be used to during Docker build phase to access your S3 bucket.     </p> </li> <li> <p>When you are ready to build your <code>Dockerfile</code>, run the following command: <code>docker build --network sagemaker --build-arg KEY=$KEY --build-arg SECRET_KEY=$SECRET_KEY -t {image_name}:{image_tag} .</code> </p> </li> </ol> <p>Note: The CI/CD is expecting these build arguments, so your Dockerfile submission must provide them. Refer to the ICD and these instructions for more information.</p> <p>Warning: For security reasons, do not push your credentials to CodeCommit.</p>"},{"location":"running_client_shell/#evaluating-your-submission-in-sagemaker","title":"Evaluating Your Submission in SageMaker","text":"<p>In order to run the evaluator, you must first authenticate your session to the AWS ECR. To authenticate, run: <code>aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 552707247569.dkr.ecr.us-east-1.amazonaws.com</code> </p> <p>Before running the evaluator, ensure that your client container is running (see Running the Client with Docker or Running the Client locally).</p> <p>Additionaly, you need to set two environment variables <code>KEY</code> and <code>SECRET_KEY</code>. These can be set by running the following the SageMaker terminal: <pre><code>export KEY=&lt;your key&gt;\nexport SECRET_KEY=&lt;your key&gt;\n</code></pre> Place these in your <code>~/.bashrc</code> to avoid having to set for every session. These are the keys used for your SageMaker login here.</p> <p>The evaluator can then be run using a convenience script in the client-shell repository: <code>eval/run_server.sh</code></p>"},{"location":"running_client_shell/#run_serversh","title":"run_server.sh","text":"<p>The <code>run_server.sh</code> script located at <code>eval/run_server.sh</code> will pull the latest <code>dtc-evaluator</code> from AWS ECR and run it. <pre><code>bash ./run_server.sh --name [EVAL_RUN_NAME] --output-dir [OUTPUT_DIR] --inventory-file [INVENTORY_FILE] --dataset-dir [DATASET_DIR] [--include-basic-ehr] [--include-expanded-ehr]\n</code></pre></p> <p>The following arguments are used to specify the data and evaluation configuration:</p> <ul> <li><code>--name</code> or <code>-n</code> specifies a name for the evaluation run. This appears in all output filenames (logs and response files) for easier tracking of separate runs.</li> <li><code>--output-dir</code> or <code>-o</code> specifies where model predictions and logs will be stored. This path can point to a location that is either local to SageMaker or your team's S3-scratch bucket.</li> <li><code>--inventory-file</code> or <code>-i</code> specifies the list of data segments to be used by the evaluator. This must be from a phase 2 dataset (phase1_v2+ or phase2_v1+). The inventory file can exist in an S3 bucket or locally. An example inventory file can be found in client_shell/eval.</li> <li><code>--dataset-dir</code> or <code>-d</code> specifies the path to the segmented dataset. This can be a local path or an S3 path. Note that this dataset must correspond to the inventory file provided above.</li> <li><code>--include-basic-ehr</code> is an optional flag that includes basic EHR data in the run for each case.</li> <li><code>--include-expanded-ehr</code> is an optional flag that includes expanded EHR data (as well as basic EHR data) in the run for each case.</li> </ul> <p>Example:  <pre><code>./run_server.sh --name test --output-dir outputs --inventory-file inventory_phase1_v2-0_val_mini.csv --dataset-dir s3://dtc-training-data/phase1/phase1_v2-0_segmented/val --include-basic-ehr\n</code></pre> This command will store evaluation outputs in the <code>./outputs</code> directory, using the <code>./inventory_phase2_v1-1_val_mini.csv</code> as the inventory file and the <code>s3://dtc-training-data/phase1_v2-0_segmented/val</code> as the source dataset with basic EHR data included for each case. Example evaluation output and logs can be found in <code>eval/example_output/out</code> and <code>eval/example_output/logs</code>, respectively.</p>"},{"location":"running_client_shell/#run_metricssh","title":"run_metrics.sh","text":"<p>The <code>run_metrics.sh</code> script located at <code>eval/run_metrics.sh</code> will compute performance metrics on the evaluation output from <code>run_server.sh</code>.</p> <p>The script saves off three files within OUTPUT_DIR/metrics:</p> <ol> <li>A ground truth CSV file containg ground truth for all segments listed in the inventory file.</li> <li>A responses JSON file containing the model's responses to all segments from the evaluation.</li> <li>A metrics JSON containing the Mean Squared Correct (MSC) metrics for each case.</li> <li>A detailed metrics CSV containing the MSC metrics for each segment.</li> <li>A threshold metrics CSV containing binary classification metrics across thresholds for each LSI group. </li> </ol> <p>See this Metrics Guide for more details on the contents of these files. </p> <p>To compute metrics for an evaluation run, first install the requirements located in <code>eval/requirements.txt</code>:</p> <pre><code>pip install -r eval/requirements.txt --timeout 1000\n</code></pre> <p>After installing the requirements, run the metrics script from within the <code>eval/</code> directory:</p> <pre><code>bash ./run_metrics.sh --output-dir [OUTPUT_DIR] --inventory-file [INVENTORY_FILE] --dataset-dir [DATASET_DIR] [--allow-incomplete]\n</code></pre> <p>The <code>output-dir</code>, <code>inventory-file</code>, and <code>dataset-dir</code> should match the inputs used for <code>run_server.sh</code>.</p> <p>If you want to run metrics on an incomplete run, you may include the optional <code>allow-incomplete</code> flag. Otherwise, the script will check to ensure all segments in the inventory file were run and throw an error if responses are missing.</p> <p>The python scripts used to generate the ground truth, response, and metrics JSONs are located in <code>eval/src</code>, but these scripts should not be altered to ensure consistent metrics with the competition.</p>"},{"location":"running_client_shell/#evaluation-resources","title":"Evaluation resources","text":"<p>Example output of the metrics can be found in <code>eval/example_output/metrics</code>.</p> <p>The config file used to create the segmented datasets is provided in <code>eval/segment_config.csv</code>. This file lists each field in the EHR data and how it is included in the segmented data at evaluation time. The CSV file has the following columns:  </p> <ul> <li>source: dataset source (\"UMB\" or \"UPitt\")  </li> <li>table: table name  </li> <li>field: field name   </li> <li>deliver-at: whether and when the field is included in the segmented data. \"start\" indicates start of case, \"timestamp\" indicates at accompanying timestamp, \"admission\" indicates at admission time, and \"exclude\" indicates it is excluded from segmented data.  </li> <li>segment-file: if the field is not excluded, the segmented data file in which it is included. This takes values: \"basic-ehr\", \"expanded-ehr\", and \"lsi\".  </li> <li>notes: accompanying notes indicating reason for inclusion/exclusion, as well as indication of new fields in the phase 2 dataset.  </li> </ul>"},{"location":"running_client_shell/#release-notes","title":"Release Notes","text":""},{"location":"running_client_shell/#v22","title":"v2.2","text":"<ul> <li>Added new weights from rules document.</li> <li>Excludes segments &gt; 60 min after hospital admission from metrics calculations.</li> <li>Added average of sensitivity/specificity benchmark.</li> <li>Added detailed metrics and threshold metrics CSVs.</li> <li>Added new example inventory file.</li> <li>NOTE: backwards compatible with old inventory and response files.</li> </ul>"},{"location":"running_client_shell/#v21","title":"v2.1","text":"<ul> <li>Updated metrics weights to balance datasets equally.</li> <li>Updated metrics with 5-minute prediction lead time.</li> <li>Added segment_config.csv with information about what EHR fields are provided during evaluation.</li> </ul>"},{"location":"running_client_shell/#v20","title":"v2.0","text":"<ul> <li>Updated metrics scripts for phase 2.</li> <li>Addition of new CLI args to run_server.sh (--include-basic-ehr, --include-expanded-ehr) with minor refactoring.</li> <li>Moved eval/ and stubs/ to top-level directory.</li> <li>Added example output from evaluator for phase 2.</li> <li>Updated Dockerfile entrypoint so it includes run_client.py for easier override of args.</li> </ul>"},{"location":"running_client_shell/#v13","title":"v1.3","text":"<ul> <li>Added ENV passable variables to evaluator and client-shell for AWS keys.</li> </ul>"},{"location":"running_client_shell/#v12","title":"v1.2","text":"<ul> <li>Added support for cpu-only base image and updated base-image tags to reflect versions.</li> <li>Added a tools directory in the client-shell with scripts to support running evaluation and metrics.</li> <li>Added instructions to the wiki for running the evaluator in SageMaker.</li> </ul>"},{"location":"running_client_shell/#v11","title":"v1.1","text":"<ul> <li>Moved dtc_messaging module to dtc-base-image repo.</li> <li>Fixed bug in message_handler CLEANUP_MESSAGE enum.</li> <li>Removed top-level \u201cresponse\u201d key from message dicts.</li> <li>Adds serialization of Numpy arrays as lists.</li> <li>Renamed Messenger.py to Client.py.</li> <li>Added purge of RabbitMQ queue during initialization of client.</li> <li>Uses new Docker base image, dtc-base-image:v1-1.</li> <li>Includes AWS CLI for copying files from S3 in Docker image.</li> <li>Creates logs directory, which will be mounted and saved off during evaluation.</li> <li>Installs latest version of dtc_messaging module.</li> <li>Added comments to Dockerfile with example setup of AWS credentials and S3 copy.</li> <li>Added .gitignore to prevent AWS credentials from being checked into repo.</li> <li>Updated send_message.py stub to match message formats used in evaluation.</li> <li>Updated template_model.py to access all possible fields expected in received messages.</li> <li>Updated README with instructions for copying from S3 during Docker build.</li> </ul>"},{"location":"running_client_shell/#v10","title":"v1.0","text":"<p>New Features:</p> <ul> <li>RabbitMQ Client: Establishes a connection to a RabbitMQ server, sets up a queue for RPC requests, and listens for incoming requests.</li> <li>Model Class: Abstract base for creating prediction models with methods for predictions, acknowledgments, end-of-case, and error scenarios. You will extend this class to implement your custom models for the evaluation. You merely need to implement four functions.</li> <li>MessageType Enum: Categorizes communication with predefined message types including connection, prediction, acknowledgment, and error handling signals.</li> <li>Message Handlers: Includes an abstract base class and specific implementations for handling various message types, ensuring appropriate communication with the evaluator.</li> <li>Factory Pattern for Message Handlers: Simplifies the creation of message handlers based on the message type, supporting scalable and modular development.</li> </ul>"},{"location":"sagemaker_instances/","title":"Recommended Instance Types for SageMaker Studio Apps","text":"<p>Applies for CodeEditor and JupyterLab instances.    </p> <p>Note: Instance and cost information are subject to change.  See the \"Details Link\" column for the most up-to-date instance details, including cost.</p> Row Instance Type CPU RAM (GiB) GPU GPU Memory (GiB) GPU Type Purpose Quota Price per Hour ($) Details Link 1 ml.t3.medium 2 4 0 0 None General Purpose 15 per team 0.05 Details 2 ml.m5.large 2 8 0 0 None General Purpose 15 per team 0.115 Details 3 ml.m5.2xlarge 8 32 0 0 None General Purpose 15 per team 0.461 Details 4 ml.c5.xlarge 4 8 0 0 None Compute Optimized 15 per team 0.204 Details 5 ml.c5.2xlarge 8 16 0 0 None Compute Optimized 15 per team 0.408 Details 6 ml.c5.9xlarge 36 72 0 0 None Compute Optimized 6 per team 1.836 Details 7 ml.r5.8xlarge 32 256 0 0 None Memory Optimized 6 per team 2.419 Details 8 ml.r5.16xlarge 64 512 0 0 None Memory Optimized 6 per team 4.838 Details 9 ml.p3.2xlarge 8 61 1 16 Tesla V100 GPU - General 6 per team 3.825 Details 10 ml.p3.8xlarge 32 244 4 64 Tesla V100 GPU - General 6 per team 14.688 Details 11 ml.g4dn.4xlarge 16 64 1 16 NVIDIA T4 GPU - General 12 per team 1.505 Details 12 ml.g4dn.8xlarge 32 128 1 16 NVIDIA T4 GPU - Training 6 per team 2.72 Details 13 ml.g5.4xlarge 16 64 1 24 AMD Radeon Pro GPU - Inference 1 per team 2.03 Details"},{"location":"submission_process/","title":"Submission Process","text":"<p>Each participant will be provisioned AWS CodeBuild Continuous Integration/Continuous Development (CI/CD) resources to provide automatic feedback regarding the submission compliance with the official evaluation system. This (CI/CD) system will containerize the submitted code using a standard buildspec and simulate a 10-case minature version of the evaluation process to assess the code\u2019s compliance. The estimated time to complete a test is ~10-15 minutes, as CodeBuild needs to queue and provision resources, and build/run containers to complete the test.</p> <p>To review the system predictions and logs of the CI/CD, the build objects will be placed in your team's scratch bucket under <code>s3://dtc-scratch-{team_name}/codebuild/</code>. The CI/CD  will store the CodeBuild logs for each unique build in the <code>build-logs/</code> directory, and the evaluation outputs in the <code>submission_results/</code> directory (i.e.  the <code>logs/</code> and <code>out/</code> directories equivalent to those produced by the dtc-server).</p> <p>Teams can trigger the CodeBuild in TWO ways:</p> <ul> <li>Compliance Test: to perform intial compliance testing during the development phase.</li> <li>Triggers: pushing updates to a team's CodeCommit branch called <code>compliance-test</code>.</li> <li> <p>Outcomes: the team's Principal Investigator will recieve an email from AWS's SNS services if the the CI/CD successfully completed.</p> </li> <li> <p>Official Event Submissions: to officially submit for an event evaluation.</p> </li> <li>Triggers: pushing updates to a team's CodeCommit with a commit tag called <code>submission-phase{PHASE_NUMBER}-{EVENT_TYPE}</code>.<ul> <li><code>PHASE_NUMBER = {1,2,3}</code></li> <li><code>EVENT_TYPE = {workshop, challenge}</code></li> </ul> </li> <li>Outcomes: if a build is successful, an email will be sent to the Principal Investigator and a docker image will be stored for review. Your previous image submission will be overwritten.</li> </ul>"},{"location":"submission_process/#logs","title":"Logs","text":"<p>While logs can be configured to save out to teams S3 bucket during development and testing in SageMaker, we will not allow logs to be written to S3 buckets during formal workshop and competition evaluations. Rather, we will copy any logs saved in the client container under <code>/usr/src/app/logs/</code> manually to teams s3 buckets following the completion of an event.  As a result, if you submit code to the CI/CD with logs saving in the client-shell to an s3 bucket, your pipeline will fail. </p> <p>At the time of the Event submission deadline, the Challenge administrators will automatically pull the images for evaluation.</p> <p>More information on the CI/CD can be found in the Data Challenge ICD.</p>"},{"location":"workspace-selfservice/","title":"AWS WorkSpaces Configuration","text":"<p>All participants have been provided with an AWS WorkSpace to facilitate SageMaker Access and local development in a streamed desktop environment. Initially, all WorkSpaces were provisioned as \"Power\" instances. We are pleased to announce that you now have the ability to self-service your WorkSpace configuration, including rebuilding, rebooting, and changing the compute type, directly from your WorkSpace client. This guide will walk you through the steps to manage your WorkSpace and explain any limitations in changing compute types.</p>"},{"location":"workspace-selfservice/#accessing-workspace-management-features","title":"Accessing WorkSpace Management Features","text":"<p>To manage your workspace, launch the AWS WorkSpaces client application on your computer and log in with your credentials.</p>"},{"location":"workspace-selfservice/#rebooting-your-workspace","title":"Rebooting Your WorkSpace","text":"<p>If your WorkSpace becomes unresponsive or you need to restart it for any reason:   </p> <ol> <li>Click on the \"Amazon Workspaces\" dropdown from within the client interface.  </li> <li>From the dropdown options, select \"Restart WorkSpace\".   </li> <li>Confirm the action to initiate the restart. The restart process will take several minutes.</li> <li>Wait for a few minutes while your WorkSpace restarts. You might need to log-in again after restart.</li> </ol> <p></p>"},{"location":"workspace-selfservice/#rebuilding-your-workspace","title":"Rebuilding Your WorkSpace","text":"<p>Rebuilding restores your WorkSpace to its original state. This is usually a last-resort step when the workspace is unresponsive or unable to connect. Important: This will erase all data and applications that are not saved on the user volume (D: drive).</p> <ol> <li>Click on the Settings dropdown from within the client interface.</li> <li>From the self-service options, select \"Rebuild WorkSpace\". Read the warning message carefully.</li> <li>Confirm the action to initiate the rebuild. The rebuild process may take up to 20 minutes.</li> </ol> <p></p>"},{"location":"workspace-selfservice/#changing-compute-type","title":"Changing Compute Type","text":"<p>You can change your WorkSpace to a different compute type to better suit your performance needs. If your administrator recently created your WorkSpace, you must wait 6 hours before you can change your WorkSpace compute type. After that, you can switch to a larger compute type once in a 6-hour period, or to a smaller compute type once in a 30-day period. </p> <ol> <li>From the self-service options, select \"Change Compute Type\".</li> <li>Choose your desired compute type from the list of available options (see the table below for details). Confirm the change when prompted.</li> <li>When your WorkSpace compute type change is in progress, you are disconnected from the WorkSpace. During this time, you can't use or make changes to the WorkSpace. This process might take up to an hour.</li> </ol> <p>Upgrading to a higher compute type may increase costs. Please review the AWS pricing details before making changes. </p> Compute Type vCPU Memory (GB) Root Volume (GB) User Volume (GB) Monthly Price (US East 1) Value 1 2 80 10 $25 Standard 2 4 80 50 $35 Performance 2 7.5 80 100 $60 Power 4 16 80 100 $125 PowerPro 8 32 80 100 $225 <p>Note: GPU WorkSpace bundles are available upon request. Note: Compute type cost information is subject to change. See the AWS pricing details for the most up-to-date compute type pricing details.</p>"}]}